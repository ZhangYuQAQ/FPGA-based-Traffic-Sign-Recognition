# FPGA-based-Traffic-Sign-Recognition
We designed a traffic sign recognition system that can recognize traffic signs quickly. 

## Team
Yu Zhang </br>
Xinye Cao 

## Things
Ultra96 v2  *1

## Story
Nowadays, the traffic network is very developed, and the traffic signs are the facilities that use graphic symbols and words to convey specific information to manage the traffic and indicate the direction of driving to ensure the smooth and safe operation of the road. Traffic signs are divided into main signs and auxiliary signs. The main signs are divided into warning signs, prohibition signs, indication signs, guide signs, tourist area signs and road construction safety signs. There are many kinds of traffic signs and their graphics are similar, so novice drivers often face great difficulties in learning. Moreover, modern urban roads crisscross each other. If the driver misreads the traffic signs, they may take the wrong road, run the red light, go retrograde, violate the stop and so on, and even may cause traffic accidents.

Under the above background, this project designs a traffic sign recognition system, which can quickly identify the traffic signs in the image according to the input image. The system can be integrated into the vehicle assistant driving system. According to the current road image information, the system can calculate the traffic prompt information contained in the front sign in real time, and feed back to the driver and other systems in time, so as to alleviate the driver's labor intensity and protect the driver's safety. This design can also be applied to intelligent transportation system to realize the interaction and coordination of people, vehicles and roads. It plays an important role in regulating traffic behavior, indicating road conditions, guiding pedestrians and driving safely, and can reduce traffic congestion and accidents to a certain extent. In addition, the traffic sign recognition system is also an important part of the automatic driving system. The traffic sign recognition system provides timely road information for vehicles by identifying traffic signs on the road in real time, and helps the automatic driving vehicle to choose the right road.

The traffic sign recognition system designed in this project has the characteristics of high accuracy and high real-time, which can meet the requirements of accuracy and real-time in most application scenarios. This design uses the lightweight neural network based on Skynet network structure to learn the traffic sign recognition task. There are 62 kinds of traffic signs in the data set, including 4572 photos in the training set (about 70 in each category) and 2520 photos (about 40 in each category) in the test data set. The accuracy of the trained network is 99% on the training set and 93.5% on the test set. In this project, the trained neural network is deployed on FPGA (pynq-z2 board) to obtain high real-time processing ability. In the hardware design, high level synthesis (HLS) is used to write the functional logic of the hardware circuit to realize the neural network structure, and the optimization instructions are added in the appropriate position to improve the parallelism of the circuit, so as to reduce the delay and make the system achieve high real-time performance.

## Attachments
This design refers to the double champion scheme of GPU and FPGA in DAC 2019 low-power target detection system design challenge, and designs a lightweight neural network suitable for traffic sign recognition task based on Skynet network structure according to the actual task needs, as shown in Fig. 2-1. In order to make full use of FPGA hardware performance, this design adopts the bottom-up method. The basic building unit of neural network is called bundle. The bundle contains some basic modules of DNN (such as convolution layer, pooling layer and activation function). We compare the characteristics of different bundles (such as computing delay, hardware resource cost and reasoning accuracy) and select the most suitable bundle. In this design, a bundle contains three main elements: dw-conv3 × 3, pw-conv1 × 1 and relu. In order to reduce the number of convolution operation parameters and reduce the computational complexity of neural network, we use the deep separate convolution to decompose a complete convolution operation into two steps: depth convolution and pointwise convolution. The processes of depth and pointwise convolution are shown in Fig. 2-2 and 2-3, respectively. There are BN layer and re layer behind each convolution layer. We build the backbone structure of neural network by stacking bundles, and then fine tune the neural network to optimize the network performance. Due to the different sizes of images in the dataset, we uniform the size of the images to 56 × 56. In this way, the cost of storage resources and the amount of calculation are reduced, and the reasoning accuracy is basically not reduced. In addition, we use global average pooling to reduce the total connection layer parameters.


The FPGA hardware platform used in this project is ultra96. The internal architecture is mainly divided into two parts: processing system (PS) with arm cortex A9 as the core and programmable logic (PL) with FPGA as the core. The hardware circuit system design of this project is shown in Figure 2-4. The hardware acceleration circuit of neural network is designed by vivado HLS at PL end, and the designed hardware circuit IP is called at PS end. Due to the limited hardware resources of FPGA, it can not make full use of all the parallelism in CNN, and sometimes even can not fully expand a single convolution layer. Therefore, only a limited number of processing units can be mapped to FPGA, and the multiplexing processing unit can be realized through temporary iteration of data. When using HLS to implement CNN hardware circuit, in order to speed up the model reasoning speed, we replace the BN layer of convolution network with a 1 × 1 convolution layer, and then fuse it with conv layer. Because the fusion of BN layer and conv layer reduces the operation, the reasoning speed of the model is improved. In this system, PS transmits the input image and network parameters to DDR DRAM, PL obtains network parameters from DDR DRAM and calculates the input image data, then transmits the recognition result back to DDR DRAM, and finally PS reads the result data from DDR DRAM.

